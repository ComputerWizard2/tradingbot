{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Ultimate 150+ Features - DreamerV3 Trading AI Training\n",
    "\n",
    "**Google Colab Training Notebook**\n",
    "\n",
    "This notebook trains a DreamerV3 agent with 136 advanced features for gold (XAUUSD) trading.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup Instructions:\n",
    "\n",
    "1. **Enable GPU:** Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU (T4, A100, or V100)**\n",
    "2. **Upload your `drl-trading` folder** to Google Drive\n",
    "3. **Run all cells** in order\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Navigate to Project Directory\n",
    "\n",
    "**IMPORTANT:** Update the path below to match where you uploaded your `drl-trading` folder in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è UPDATE THIS PATH to match your Google Drive structure\n",
    "PROJECT_PATH = '/content/drive/MyDrive/drl-trading'\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
    "print(f\"üìÅ Files in directory:\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install pandas numpy tqdm matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"üñ•Ô∏è  PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GPU not available! Using CPU (will be slow)\")\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"\\n‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Quick Feature Test (Optional)\n",
    "\n",
    "Test that the feature system works before starting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.ultimate_150_features import make_ultimate_features\n",
    "\n",
    "print(\"üß™ Testing feature generation...\")\n",
    "print(\"This will take ~2 minutes (processing 709k bars)\\n\")\n",
    "\n",
    "X, returns, timestamps = make_ultimate_features(base_timeframe='M5')\n",
    "\n",
    "print(\"\\n‚úÖ SUCCESS!\")\n",
    "print(f\"üìä Total features: {X.shape[1]}\")\n",
    "print(f\"üìä Total samples: {X.shape[0]:,}\")\n",
    "print(f\"üíæ Memory usage: {X.nbytes / 1024**2:.1f} MB\")\n",
    "print(f\"üìÖ Date range: {timestamps[0]} to {timestamps[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Start Training!\n",
    "\n",
    "### Training Configurations:\n",
    "\n",
    "**Quick Test (10 minutes):**\n",
    "- Steps: 10,000\n",
    "- Good for testing the pipeline\n",
    "\n",
    "**Short Training (1-2 hours):**\n",
    "- Steps: 100,000\n",
    "- Will show initial learning\n",
    "\n",
    "**Full Training (5-7 hours on A100, 12-15 hours on T4):**\n",
    "- Steps: 1,000,000\n",
    "- Production-ready model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your training configuration\n",
    "TRAINING_STEPS = 1_000_000  # Change to 10_000 for quick test, 100_000 for short training\n",
    "BATCH_SIZE = 128 if device == 'cuda' else 16  # Larger batch on GPU\n",
    "\n",
    "print(f\"üèãÔ∏è  Training Configuration:\")\n",
    "print(f\"   ‚Ä¢ Steps: {TRAINING_STEPS:,}\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Device: {device}\")\n",
    "print(f\"\\n‚è±Ô∏è  Estimated time:\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if 'A100' in gpu_name:\n",
    "        time_estimate = TRAINING_STEPS / 1_000_000 * 5  # ~5 hours for 1M steps on A100\n",
    "    elif 'V100' in gpu_name:\n",
    "        time_estimate = TRAINING_STEPS / 1_000_000 * 8  # ~8 hours for 1M steps on V100\n",
    "    else:  # T4\n",
    "        time_estimate = TRAINING_STEPS / 1_000_000 * 12  # ~12 hours for 1M steps on T4\n",
    "    print(f\"   ‚Ä¢ ~{time_estimate:.1f} hours on {gpu_name}\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ CPU training will be VERY slow (not recommended)\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Make sure Colab stays open (or use Colab Pro+ for background execution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train/train_ultimate_150.py \\\n",
    "    --steps {TRAINING_STEPS} \\\n",
    "    --device {device} \\\n",
    "    --batch-size {BATCH_SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Resume Training (if interrupted)\n",
    "\n",
    "If training gets interrupted, you can resume from the last checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available checkpoints\n",
    "!ls -lh train/dreamer_ultimate/*.pt | tail -5\n",
    "\n",
    "# Resume from latest checkpoint\n",
    "# UPDATE the checkpoint path below\n",
    "CHECKPOINT_PATH = \"train/dreamer_ultimate/ultimate_150_xauusd_step_10000.pt\"\n",
    "\n",
    "!python train/train_ultimate_150.py \\\n",
    "    --steps {TRAINING_STEPS} \\\n",
    "    --device {device} \\\n",
    "    --batch-size {BATCH_SIZE} \\\n",
    "    --resume {CHECKPOINT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Download Trained Model\n",
    "\n",
    "After training completes, download your model to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "# Find the latest checkpoint\n",
    "checkpoints = sorted(glob.glob('train/dreamer_ultimate/*.pt'))\n",
    "if checkpoints:\n",
    "    latest_checkpoint = checkpoints[-1]\n",
    "    print(f\"üì• Downloading: {latest_checkpoint}\")\n",
    "    files.download(latest_checkpoint)\n",
    "    print(\"‚úÖ Download complete!\")\n",
    "else:\n",
    "    print(\"‚ùå No checkpoints found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Monitor Training (Optional)\n",
    "\n",
    "View training progress and GPU usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Expected Training Time\n",
    "\n",
    "| GPU Type | 1M Steps | 100K Steps | 10K Steps |\n",
    "|----------|----------|------------|----------|\n",
    "| A100 (40GB) | 5-7 hours | 30-45 min | 3-5 min |\n",
    "| V100 (16GB) | 8-10 hours | 50-60 min | 5-8 min |\n",
    "| T4 (16GB) | 12-15 hours | 70-90 min | 7-10 min |\n",
    "| CPU | 7-10 days | 16-20 hours | 1-2 hours |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips:\n",
    "\n",
    "1. **Colab Pro/Pro+:** Get longer runtimes and better GPUs\n",
    "2. **Keep tab open:** Colab may disconnect if inactive (unless you have Pro+)\n",
    "3. **Save checkpoints:** Models are saved every 10,000 steps\n",
    "4. **Monitor GPU:** Check `nvidia-smi` to ensure GPU is being used\n",
    "5. **Download frequently:** Download checkpoints periodically to avoid losing progress\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Next Steps After Training:\n",
    "\n",
    "1. Download the trained model checkpoint\n",
    "2. Test on validation data (2022-2023)\n",
    "3. Backtest on out-of-sample data (2024-2025)\n",
    "4. Deploy for live trading\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
